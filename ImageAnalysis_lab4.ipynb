{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# uncomment below if you want bigger resolution images\n",
    "#plt.rcParams['figure.dpi'] = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Analysis Basics\n",
    "In this notebook, we will learn how to do basic image operations such as thresholding, segmentation and smoothing/denoising of images with basic python functionalities. Here are some of the specific learning objectives:\n",
    "\n",
    "1. Loading and plotting images and datasets with python commands\n",
    "2. Array operations with images such as thresholding (usually the first step in most imaging analysis workflow)\n",
    "3. Basic theory behind convolution and use it to create filters. We will use these to:\n",
    "    * Explore the effects of various kinds of local averaging on an image;\n",
    "    * Use specialized filters to emphasize specific features in an image.\n",
    "4. Use statistical tools to do a basic image classification problem (an example of classical Machine Learning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image and data files\n",
    "The data files you will need for this notebook can be found on the catcourses module page for Day 4.  Please copy the contents of that folder into your working directory i.e. where this notebook is hosted. First let's look at the contents of \"bwCat.tif\". These files were originally downloaded from http://physicalmodelingwithpython.blogspot.com/p/data-sets.html from the datasets 16 and 17, which also includes the README files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the image file. This is usually in formats such as tif, jpg, png,.....\n",
    "photo = plt.imread('bwCat.tif')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do the following to check the attributes of the variable called \"photo\"\n",
    "\n",
    "1.Output it explicitly and see that it is an array of numbers.\n",
    "\n",
    "2.Find the shape of the array using photo.shape (that corresponds to the number of pixels) \n",
    "\n",
    "3.Check the type of the array using photo.dtype \n",
    "\n",
    "4.recap how to take a slice of the array, say the top left square of ten elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# execute plt.imshow(photo) to actually see the cat!\n",
    "#plt.imshow(photo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "168"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us switch to gray scale because that's what the simple image analysis tools are applicable to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.set_cmap('gray') # Use grayscale for black and white image.\n",
    "#plt.axis('off') # Get rid of axes and tick marks.\n",
    "#fig = plt.gcf() # Get current figure object.\n",
    "#fig.set_facecolor('white') # Set border color to b\n",
    "#plt.imshow(photo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a binary image called \"new_cat\" by choosing lighter pixels to be ones and darker pixels to be zero.  This is a common strategy to do thresholding on an image, i.e. isolate the darker and lighter parts of an image, which in turn can be a strategy to segmenting of an image, i.e. to separate it into discrete objects, such as background and foreground."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert to binary\n",
    "#new_cat = (photo > photo.mean())\n",
    "#new_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(new_cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolution: Image Smoothing\n",
    "If you've ever played with photographic software such as GIMP(or a commercial alternative like Photoshop), you've probably used *convolutions* to smooth or sharpen, images but perhaps you didn't know it.\n",
    "The mathematical definition of convolving two functions (originally comes from probability theory and gives the probability distribution of the sum of two random variables each with its own probability distribution)\n",
    "$$ (f*g)(n) = \\Sigma_l f(l) g(n-l) $$\n",
    "where the value of the indices, l and n-l, in the summation, range over all possible values where the functions are define.\n",
    "So for example f is a 1D array of size L, and g is a 1D array of size N, the index of the array (f*g) can range to nmax, such that $nmax-L = N-1$, or in other words, the size of the convolved array is $N+L-1$.\n",
    "In the image analysis context, we convolve the image array I with a filter array F in the following way:\n",
    "$$ C_{i,j} = \\Sigma_l F_{k,l} I_{i-k, j-l}$$\n",
    "\n",
    "A visual illustration of this is offered by the following:\n",
    "<img src=\"stride1.gif\" width=\"400\" height=\"480\">\n",
    "which shows intuitively what multiplying by F does. It averages every element of I with those of its neighbors with weights specified by F.\n",
    "\n",
    "Two important identities follow:\n",
    "1. The trivial transformation, for which F is a 1by1 matrix with\n",
    "a single entry equal to 1, is identity i.e. it gives back the original image.\n",
    "2. Suppose that the size of F is $m \\times n$, and that of I is $M \\times N$, the size of C is $(M + m - 1) \\times (N + n - 1)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.ndimage as sim  # SciPy image library has built-in convolution functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim.convolve?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab, you will explore several filters and convolutions. As you proceed through the exercises,\n",
    "you will see a photograph transformed by each operation. To get an idea of what is happening on a\n",
    "pixel-by-pixel level, you can apply the same convolution to a single dot. (This is the impulse response\n",
    "of the filter.) This will allow you to see the shape of the filter and better understand what you are\n",
    "doing to the photograph. Try the impuls-response below.\n",
    "Use the subplots function to plot the impulse and the response side-by-side."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "impulse = np.zeros( (51, 51) )\n",
    "impulse[25, 25] = 1.0\n",
    "my_filter = np.ones( (3, 3) ) / 9\n",
    "response = sim.convolve(impulse, my_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.subplot(121)\n",
    "plt.imshow(impulse)\n",
    "plt.subplot(122)\n",
    "plt.imshow(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above was an example of a square filter. Now define a larger square filter by 15 by 15. Apply both small and large square filters\n",
    "to the cat image stored in the variable *photo* using sim.convolve and plot the small and large square filter results side-by-side."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "large_square_filter = np.ones((15,15))/225\n",
    "small_square_filter = np.ones( (3, 3) ) / 9\n",
    "\n",
    "photo_large_square = sim.convolve(photo,large_square_filter )\n",
    "photo_small_square = sim.convolve(photo,small_square_filter )\n",
    "\n",
    "plt.figure()\n",
    "plt.subplot(121)\n",
    "plt.imshow(photo_small_square)\n",
    "plt.subplot(122)\n",
    "plt.imshow(photo_large_square)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### gaussian filter\n",
    "\n",
    "Now we will look at a slightly more complex filter, called a Gaussian filter. L\n",
    "\n",
    "a.Load the provided file gauss_filter.csv into a NumPy array called gauss.\n",
    "\n",
    "b. Use plt.imshow to compare the convolutions of a single dot with a Gaussian filter and the\n",
    "square filter you used before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load gauss_filter.csv\n",
    "gauss= np.loadtxt('gauss_filter.csv', delimiter = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare Gaussian and square filters on single dot (impulse defined before)\n",
    "plt.figure()\n",
    "plt.subplot(121)\n",
    "plt.imshow(sim.convolve(impulse,gauss))\n",
    "plt.subplot(122)\n",
    "plt.imshow(sim.uniform_filter(impulse,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Emphasizing features\n",
    "\n",
    "In between \\features\" (real things of interest to us) and \\noise\" (random things), experimental\n",
    "images may contain things that are real, but not of interest to us. We may wish to deemphasize\n",
    "such things, or we may wish to quantify some visual feature.\n",
    "As an example, we look at how Zemel and coauthors sought to quantify the extent to which the\n",
    "cell was polarized, at every point in the cell (https://www.nature.com/articles/nphys1613).\n",
    "We work with the data set 17stressFibers,\n",
    "README.txt and stressFibers.csv which should be in your working directory.  The image shows the long, slender stress fibers. We will now construct and apply a filter that\n",
    "emphasizes long, slender objects that are oriented vertically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.loadtxt and plot the image\n",
    "stressFibers = np.loadtxt('stressFibers.csv', delimiter = ',')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we make our custom made filter to emphasize elongated slender structures and test it out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convolution.py [get code]\n",
    "v = np.arange(-25, 26)\n",
    "X, Y = np.meshgrid(v, v)\n",
    "gauss_filter = np.exp(-0.5*(X**2/2 + Y**2/45))\n",
    "laplace_filter = np.array( [[0, -1, 0], [-1, 4, -1], [0, -1, 0]])\n",
    "combined_filter  = sim.convolve(gauss_filter, laplace_filter)\n",
    "#%% Create a plus sign '+' to demonstrate effect of filter.\n",
    "plus = np.zeros((51, 51))\n",
    "plus[23:28, 25] = 1.0\n",
    "plus[25, 23:28] = 1.0\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(plus)\n",
    "plt.gray()\n",
    "\n",
    "#%%\tApply filter to '+' and display resulting image.\n",
    "#\tUse vmin/vmax to emphasize features within a restricted range of intensity.\n",
    "cplus = sim.convolve(plus, combined_filter)\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(cplus, vmin=0, vmax=0.5*cplus.max())\n",
    "plt.gray()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rescale array values to between 0 and 255\n",
    "#stressFibers.shape\n",
    "new = 255*(stressFibers - np.min(stressFibers))/np.max(stressFibers)\n",
    "plt.imshow(new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now use sim.convolve to apply the filter to the fiber image, display your results, and comment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnew = sim.convolve(new, combined_filter)\n",
    "plt.imshow(cnew, vmin=0, vmax=0.5*cnew.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make horizontal filter\n",
    "\n",
    "#apply to stressFibers and plot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make 45 degrees filter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image classification using scikitlearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "\n",
    "from IPython.core.display import Image, display\n",
    "display(Image(filename= 'iris_setosa.jpg'))\n",
    "print(\"Iris Setosa\\n\")\n",
    "\n",
    "display(Image(filename='iris_versicolor.jpg'))\n",
    "print(\"Iris Versicolor\\n\")\n",
    "\n",
    "display(Image(filename='iris_virginica.jpg'))\n",
    "print(\"Iris Virginica\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 4)\n",
      "(150,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()\n",
    "\n",
    "print(iris.data.shape)\n",
    "print(iris.target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose any two features so that the data can be represented as a 2D plot\n",
    "x_index = 0\n",
    "y_index = 1\n",
    "\n",
    "# this formatter will label the colorbar with the correct target names\n",
    "formatter = plt.FuncFormatter(lambda i, *args: iris.target_names[int(i)])\n",
    "\n",
    "plt.scatter(iris.data[:, x_index], iris.data[:, y_index],\n",
    "            c=iris.target, cmap=plt.cm.get_cmap('RdYlBu', 3))\n",
    "plt.colorbar(ticks=[0, 1, 2], format=formatter)\n",
    "plt.clim(-0.5, 2.5)\n",
    "plt.xlabel(iris.feature_names[x_index])\n",
    "plt.ylabel(iris.feature_names[y_index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quick Exercise:\n",
    "\n",
    "In the cells below,\n",
    "**Change** `x_index` **and** `y_index` in the above script\n",
    "and find a combination of two parameters\n",
    "which maximally separate the three classes. Try two cases.\n",
    "\n",
    "This exercise is a preview of **dimensionality reduction**, which we'll see soon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find a pair of features that seem to separate the three flower species when p\n",
    "# Choose any two features so that the data can be represented as a 2D plot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dimensionality Reduction: PCA\n",
    "\n",
    "Principle Component Analysis (PCA) is a dimension reduction technique that can find the combinations of variables that explain the most variance.\n",
    "\n",
    "Consider the iris dataset. It cannot be visualized in a single 2D plot, as it has 4 features. We are going to extract 2 combinations of sepal and petal dimensions to visualize it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reduced dataset shape: (150, 2)\n"
     ]
    }
   ],
   "source": [
    "X, y = iris.data, iris.target\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=0.95)\n",
    "#pca = PCA(n_components=None)\n",
    "#pca = PCA(n_components=2)\n",
    "pca.fit(X)\n",
    "X_reduced = pca.transform(X)\n",
    "print(\"Reduced dataset shape:\", X_reduced.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn.decomposition.PCA?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X_reduced[:, 0], X_reduced[:, 1], c=y,\n",
    "           cmap='RdYlBu')\n",
    "\n",
    "print(\"Meaning of the 2 components:\")\n",
    "for component in pca.components_:\n",
    "    print(\" + \".join(\"%.3f x %s\" % (value, name)\n",
    "                     for value, name in zip(component,\n",
    "                                            iris.feature_names)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supervised Learning: Classification and Regression\n",
    "\n",
    "In **Supervised Learning**, we have a dataset consisting of both **features** and **labels**.\n",
    "The task is to construct an estimator which is able to predict the label of an object\n",
    "given the set of features. A relatively simple example is predicting the species of \n",
    "iris given a set of measurements of its flower. This is a relatively simple task. \n",
    "Some more complicated examples are:\n",
    "\n",
    "- given a multicolor image of an object through a telescope, determine\n",
    "  whether that object is a star, a quasar, or a galaxy.\n",
    "- given a photograph of a person, identify the person in the photo.\n",
    "- given a list of movies a person has watched and their personal rating\n",
    "  of the movie, recommend a list of movies they would like\n",
    "  (So-called *recommender systems*: a famous example is the [Netflix Prize](http://en.wikipedia.org/wiki/Netflix_prize)).\n",
    " - What are some examples of useful application in Biophysics/Bioscience research? \n",
    " (We'll revisit this question at the end of the lecture.)\n",
    "  \n",
    "  Supervised learning is further broken down into two categories, **classification** and **regression**.\n",
    "In classification, the label is discrete, while in regression, the label is continuous. For example,\n",
    "in astronomy, the task of determining whether an object is a star, a galaxy, or a quasar is a\n",
    "classification problem: the label is from three distinct categories. On the other hand, we might\n",
    "wish to estimate the age of an object based on such observations: this would be a regression problem,\n",
    "because the label (age) is a continuous quantity.\n",
    "  \n",
    "See [SciKit tutorial](https://github.com/jakevdp/sklearn_tutorial) for examples of regression. Essentially, data-fitting that we do in a typical intro physics lab class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
